\documentclass{beamer}
\beamertemplatenavigationsymbolsempty
\usecolortheme{beaver}
\setbeamertemplate{blocks}[rounded=true, shadow=true]
\setbeamertemplate{footline}[page number]
%
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amssymb,amsfonts,amsmath,mathtext}
\usepackage{subfig}
\usepackage[all]{xy} % xy package for diagrams
\usepackage{array}
\usepackage{multicol}% many columns in slide
\usepackage{hyperref}% urls
\usepackage{hhline}%tables
\usepackage{natbib}
\usepackage{natbib}
\usepackage{doi}
\usepackage{mathtools}
% Your figures are here:
\graphicspath{ {fig/} {../fig/} }

%----------------------------------------------------------------------------------------------------------
\title[\hbox to 56mm{Декодирование сигналов головного мозга в аудиоданные}]{Декодирование сигналов головного мозга в аудиоданные}
\author[М.\,Ф. Набиев]{Набиев Мухаммадшариф Фуркатович}
\institute{Московский физико-технический институт}
\date{\footnotesize
\par\smallskip\emph{Курс:} Моя первая научная статья\par (практика, В.\,В.~Стрижов)
% \par\smallskip\emph{Инновационный практикум:} Научный трек
\par\smallskip\emph{Руководитель:} аспирант П.\,А.~Северилов
\par\bigskip\small 2024}
%----------------------------------------------------------------------------------------------------------
\begin{document}
%----------------------------------------------------------------------------------------------------------
\begin{frame}
\thispagestyle{empty}
\maketitle
\end{frame}
%-----------------------------------------------------------------------------------------------------
\begin{frame}{Цель исследования}
%\begin{block}{Решается задача}
%\end{block}
\textbf{Цель:} Исследовать влияние физико-информированных энкодеров на качество декодирвование мозговых сигналов в аудиоданные. \\
\textbf{Задача:} Решить задачу декодирования в постановке классификации, а именно определить, какой сегмент аудио вызвал конкретную мозговую активность.
\begin{figure}
    \centering
    \includegraphics[width=0.75\textwidth]{task_matchmismatch.png}
\end{figure}
\end{frame}
%-----------------------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------------------------
\begin{frame}{Постановка задачи}
\textbf{Данные:} Кортеж $(\mathbf{X}^i, \mathbf{s}_1^i, \dots, \mathbf{s}_K^i)$, где $\mathbf{X}^i \in \mathbb{R}^{64 \times T}$~--- ЭЭГ-сигнал с 64 каналами, $\mathbf{s}_1^i, \dots, \mathbf{s}_K^i \in \mathbb{R}^{T}$--- стимулы, а $K$~--- количество стимулов. Меткой данного объекта будет являться вектор $\mathbf{y}^i \in \{0, 1\}^K$. Только один стимул является истинным. \bigskip

Требуется по имеющимся $\mathbf{X}^i, \mathbf{s}_1^i, \dots, \mathbf{s}_K^i$ получить распределение вероятностей стимулов $\mathbf{p}^i = [p_1^i, \dots , p_K^i]^T$. Пусть модель представляет собой следующее отображение $\mathbf{f} : \mathbb{R}^{64 \times T} \times \left( \mathbb{R}^{T} \right)^K \rightarrow [0, 1]^K$. Задача сводится к минимизации кросс-энтропии:
    $$CE = - \frac{1}{N}\sum_{i=1}^N\sum_{k=1}^K y_k^i \log \left( \left[ \mathbf{f}(\mathbf{X}^i, \mathbf{S}^i) \right]_k \right),$$
    где $\mathbf{S}^i = (\mathbf{s}^i_1, \dots, \mathbf{s}^i_K)$. То есть решается задача мультиклассовой классификации.

\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Архитектура решения}
% \includegraphics[width=0.90\textwidth]{model_architecture.png}
\begin{figure}[t]
        \centering
        \includegraphics[width=1\textwidth]{model_architecture.png}
\end{figure}
\begin{columns}[c]
\column{0.5\textwidth}
     \textbf{Базовое решение:} Расширенная CNN ~--- энкодер, который переводит ЭЭГ и стимулы в латентные пространства, где считается их близость (см.~\citep{Accou2021ModelingTR}).
\column{0.5\textwidth}
     \textbf{Предлагаемые улучшения:}
     Для ЭЭГ заменить CNN на трансформер-кодировщик и использовать физико-информированный энкодер для стимула (см.~\citep{multihead-gru}). 
\end{columns}
\end{frame}
%----------------------------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Данные для эксперимента}
Эксперимент будет проверяться на данных SparrKULee (см.~\citep{K3VSND_2023}).
\begin{itemize}
     \item \textbf{Участники:} 85 участников.
    \item \textbf{Стимулы:} 6-10 аудиофрагментов разной категории, такие как аудиокниги и подкасты, каждый длительностью  $\approx15$ минут.
\end{itemize}
\bigskip
После обработки, частота дискретизации  данных была понижена до 64 Гц. Для проведения эксперимента были случайно отобраны 22 участника с одинаковым количеством мужчин и женщин. 
% \begin{figure}
%     \centering
%     \includegraphics[width=0.5\textwidth]{envelope_example.png}
%     \caption{Пример огибающей сигнала}
% \end{figure}
\end{frame}

\begin{frame}{Данные для эксперимента}
\begin{figure}[t]
    \centering
    \includegraphics[width=1\textwidth]{signal_envelope.png}
\end{figure}
Для предложенной модели был взят аудиосигнал, а для базовой модели ее огибающая. В дальнейшем сегмент сигнала или её огибающей и будет называться стимулом.
\end{frame}

\begin{frame}{Данные для эксперимента}
\begin{columns}
\column{0.5\textwidth}
\includegraphics[width=1\textwidth]{train_test.png}
\column{0.5\textwidth}
Все данные были разделены в соотношении 80:20. 
Объединение частей с начала сигнала было использовано в качестве обучающей выборки, а объединение частей с конца было использовано в качестве тестовой выборки (см. рисунок и~\citep{Accou2021ModelingTR}).
\end{columns}
\end{frame}

\begin{frame}{Подготовка данных}
\begin{figure}[t]
    \centering
    \includegraphics[width=1\textwidth]{imposters.png}
\end{figure}
Стимул вызвавший активность в мозге в соответствующий промежуток времени называется истинным, а остальные --- ложные. Для генерации ложных стимулов были взяты стимулы из других пар (ЭЭГ,стимул).
\end{frame}


\begin{frame}{Вычислительный эксперимент}
Параметры эксперимента: 
\begin{itemize}
    \item Размер окна - 5 секунд
    \item Шаг окна - 1 секунда 
    \item Количество ложных стимулов - 4
    \item Модель Wav2Vec2.0 - wav2vec2-base-960h-phoneme-reco-dutch
    \item Модель Whisper - whisper-small
\end{itemize}
Количество кортежей в обучающей выборке составило 612500, а в тестовой выборке 150075.

\end{frame}


\begin{frame}{Результаты эксперимента}
Обозначим множество классов, как $\{0, \dots, K-1\}$. Учитывая это, метрика качества вычисляется по формуле
$$
    Score = \frac{1}{22} \sum_{i=1}^{22} \frac{1}{l_i} \sum_{j=1}^{l_i} \left[ y^i_j = pred^i_j\right],
$$
где $y^i_j \in \{0, \dots, K-1\}$~--- метка объекта, $l_i$~--- количество кортежей для $i$-го участника, а $pred^i_j$~--- предсказание модели на объекте $j$.
\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|} \hline 
        Model & Score (\%) \\ \hline
        Baseline & 47.68 $\pm$ 11.75 \\ 
        Transformer Encoder & 48.15 $\pm$ 10.33 \\ 
        Wav2Vec2 & 47.92 $\pm$ 11.54 \\   
        Whisper-small & 48.04 $\pm$ 9.85 \\   
        Transformer Encoder + Wav2Vec2 & \textbf{48.70} $\pm$ 9.44 \\ 
        Transformer Encoder + Whisper-small & 48.36 $\pm$ 9.24\\ \hline
    \end{tabular}
    \label{results}
\end{table}

\end{frame}

\begin{frame}{Результаты эксперимента}
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{boxplot_results.png}
    \caption{Диаграмма размаха для тестовых данных}
\end{figure}
Наилучший результат был получен за счет комбинирования Wav2Vec2.0 и трансформера-кодировщика.
\end{frame}

% \begin{frame}{Заключение}
% \begin{itemize}
%     \item Учет физических особенностей голоса увеличивает качество предсказания. 
    
% \end{itemize}
% \end{frame}


%----------------------------------------------------------------------------------------------------------
% \begin{frame}{Дальнейшие планы}
%     \begin{itemize}
%         \item Добавить энкодеры для стимулов: conformer, whisper, wav2vec
%         \item
%     \end{itemize}
% \end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{Источники}
    \bibliographystyle{plain}
    \bibliography{Nabiev2024SignalToAudio}
\end{frame}
\end{document} 
%-----------------------------------------------------------------------------------------------------


\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{���������� ������}
\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{�������}
\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{�������������� �����������}
\end{frame}
%----------------------------------------------------------------------------------------------------------
\begin{frame}{����������}
\end{frame}
%----------------------------------------------------------------------------------------------------------
\end{document} 