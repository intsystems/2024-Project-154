{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fg5GvKa0qXkT"
   },
   "source": [
    "# Установка нужных библиотек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7P4TWOOmqXkY"
   },
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4EVJmkwOqXkY",
    "ExecuteTime": {
     "end_time": "2024-04-03T12:20:27.982302Z",
     "start_time": "2024-04-03T12:20:23.962189Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 15:20:26.102276: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-03 15:20:26.883476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.mylib.models.models import BaselineModel, MHAModel\n",
    "from src.mylib.train import Trainer\n",
    "\n",
    "file = os.path.abspath('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2HeCQ89qXkZ"
   },
   "source": [
    "# Работа с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Начальные параметры"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Длина окна\n",
    "window_length_seconds = 5 \n",
    "sample_rate = 64\n",
    "window_length = window_length_seconds * sample_rate\n",
    "\n",
    "# Расстояние между двумя окнами\n",
    "hop_length_seconds = 1\n",
    "hop_length = sample_rate * hop_length_seconds\n",
    "\n",
    "# Количество ложные стимулов\n",
    "number_of_mismatch = 4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:20:27.986925Z",
     "start_time": "2024-04-03T12:20:27.983711Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "experiment_folder = os.path.dirname(file)\n",
    "\n",
    "# Load the config file\n",
    "with open(os.path.join(experiment_folder, \"src/mylib/utils/config.json\")) as file_path:\n",
    "    config = json.load(file_path)\n",
    "\n",
    "# Path to the dataset, which is already split to train, val, test\n",
    "data_folder = os.path.join(config[\"dataset_folder\"], config['derivatives_folder'], config[\"split_folder\"])\n",
    "\n",
    "# Пути к данным тренировочным, валидационным и тестовым данным\n",
    "train_files = [x for x in glob.glob(os.path.join(data_folder, \"train_-_*\")) if\n",
    "                       os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in [\"eeg\", \"envelope\"]]\n",
    "val_files = [x for x in glob.glob(os.path.join(data_folder, \"val_-_*\")) if\n",
    "                       os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in [\"eeg\", \"envelope\"]]\n",
    "test_files = [x for x in glob.glob(os.path.join(data_folder, \"test_-_*\")) if\n",
    "                       os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in [\"eeg\", \"envelope\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:20:27.999209Z",
     "start_time": "2024-04-03T12:20:27.988090Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19nb_usNqXkc"
   },
   "source": [
    "## Обучение "
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# model = BaselineModel()\n",
    "args = {\"window_length\" : window_length, \"hop_length\" : hop_length, \"number_of_mismatch\" : number_of_mismatch, \"batch_size\" : batch_size, \n",
    "        \"max_files\" : None}\n",
    "for model in [BaselineModel, MHAModel]:\n",
    "    model = model()\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model, train_files, val_files, test_files, args, torch.optim.Adam(model.parameters(), lr=0.001) \n",
    "    )\n",
    "\n",
    "    trainer.train_model(epochs=2, run_name=f\"{model.__class__.__name__}\", eps=1e-5)\n",
    "    trainer.test(window_length, hop_length, number_of_mismatch, None)\n",
    "    print(\"-----\" * 10)"
   ],
   "metadata": {
    "id": "ZMK7mqNQZPXJ",
    "outputId": "a95524d6-db85-4a34-9c36-fa2befec2f34",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-04-03T12:30:52.236219Z",
     "start_time": "2024-04-03T12:20:28.000137Z"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: BaselineModel\n",
      "EPOCH 1:\n",
      "  batch 100 loss: 0.10230839826722066\n",
      "  batch 200 loss: 0.00040566950565384176\n",
      "  batch 300 loss: 0.00019768533426147594\n",
      "  batch 400 loss: 2.5900446552251656e-06\n",
      "LOSS train 2.5900446552251656e-06 valid 4.137537594234935e-05\n",
      "EPOCH 2:\n",
      "  batch 100 loss: 0.0001946311015124791\n",
      "  batch 200 loss: 7.989311695837387e-06\n",
      "LOSS train 7.989311695837387e-06 valid 3.112558865379723e-05\n",
      "sub-036\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-076\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-017\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-064\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-042\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-029\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-078\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-022\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-005\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-011\n",
      "    Mean accuracy per subject: 99.87893462469734\n",
      "sub-014\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-013\n",
      "    Mean accuracy per subject: 99.87893462469734\n",
      "sub-033\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-021\n",
      "    Mean accuracy per subject: 99.87730061349693\n",
      "sub-030\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-073\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-001\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-085\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-075\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-072\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-062\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-024\n",
      "    Mean accuracy per subject: 99.87893462469734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14602\n",
      "           1       1.00      1.00      1.00     14602\n",
      "           2       1.00      1.00      1.00     14602\n",
      "           3       1.00      1.00      1.00     14602\n",
      "           4       1.00      1.00      1.00     14602\n",
      "\n",
      "    accuracy                           1.00     73010\n",
      "   macro avg       1.00      1.00      1.00     73010\n",
      "weighted avg       1.00      1.00      1.00     73010\n",
      "\n",
      "--------------------------------------------------\n",
      "Model: MHAModel\n",
      "EPOCH 1:\n",
      "  batch 100 loss: 0.12953224526091442\n",
      "  batch 200 loss: 0.001703386658460465\n",
      "  batch 300 loss: 0.002718644838108157\n",
      "  batch 400 loss: 0.0009678898562079896\n",
      "  batch 500 loss: 0.0001987801142964951\n",
      "  batch 600 loss: 0.00013222929090213497\n",
      "  batch 700 loss: 4.238304099253299e-06\n",
      "LOSS train 4.238304099253299e-06 valid 4.414944674487928e-08\n",
      "sub-036\n",
      "    Mean accuracy per subject: 99.40915805022156\n",
      "sub-076\n",
      "    Mean accuracy per subject: 99.08925318761385\n",
      "sub-017\n",
      "    Mean accuracy per subject: 100.0\n",
      "sub-064\n",
      "    Mean accuracy per subject: 99.37402190923318\n",
      "sub-042\n",
      "    Mean accuracy per subject: 99.3485342019544\n",
      "sub-029\n",
      "    Mean accuracy per subject: 99.5253164556962\n",
      "sub-078\n",
      "    Mean accuracy per subject: 99.4535519125683\n",
      "sub-022\n",
      "    Mean accuracy per subject: 99.6319018404908\n",
      "sub-005\n",
      "    Mean accuracy per subject: 99.46595460614152\n",
      "sub-011\n",
      "    Mean accuracy per subject: 98.91041162227603\n",
      "sub-014\n",
      "    Mean accuracy per subject: 99.6319018404908\n",
      "sub-013\n",
      "    Mean accuracy per subject: 99.15254237288136\n",
      "sub-033\n",
      "    Mean accuracy per subject: 99.26144756277695\n",
      "sub-021\n",
      "    Mean accuracy per subject: 99.6319018404908\n",
      "sub-030\n",
      "    Mean accuracy per subject: 99.68354430379746\n",
      "sub-073\n",
      "    Mean accuracy per subject: 99.63570127504553\n",
      "sub-001\n",
      "    Mean accuracy per subject: 99.15254237288136\n",
      "sub-085\n",
      "    Mean accuracy per subject: 99.10394265232975\n",
      "sub-075\n",
      "    Mean accuracy per subject: 99.08925318761385\n",
      "sub-072\n",
      "    Mean accuracy per subject: 99.4535519125683\n",
      "sub-062\n",
      "    Mean accuracy per subject: 99.01800327332242\n",
      "sub-024\n",
      "    Mean accuracy per subject: 99.39467312348668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     14602\n",
      "           1       0.99      0.99      0.99     14602\n",
      "           2       0.99      0.99      0.99     14602\n",
      "           3       0.99      0.99      0.99     14602\n",
      "           4       0.99      0.99      0.99     14602\n",
      "\n",
      "    accuracy                           0.99     73010\n",
      "   macro avg       0.99      0.99      0.99     73010\n",
      "weighted avg       0.99      0.99      0.99     73010\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "colab": {
   "name": "main.ipynb",
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
