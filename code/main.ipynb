{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fg5GvKa0qXkT"
   },
   "source": [
    "# Установка нужных библиотек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7P4TWOOmqXkY"
   },
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4EVJmkwOqXkY",
    "ExecuteTime": {
     "end_time": "2024-04-01T17:21:48.882165Z",
     "start_time": "2024-04-01T17:21:45.522872Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 20:21:47.470487: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-01 20:21:48.253379: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.mylib.models.models import BaselineModel, MHAModel\n",
    "from src.mylib.train import Trainer\n",
    "\n",
    "file = os.path.abspath('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2HeCQ89qXkZ"
   },
   "source": [
    "# Работа с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Начальные параметры"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Длина окна\n",
    "window_length_seconds = 5 \n",
    "sample_rate = 64\n",
    "window_length = window_length_seconds * sample_rate\n",
    "\n",
    "# Расстояние между двумя окнами\n",
    "hop_length_seconds = 1\n",
    "hop_length = sample_rate * hop_length_seconds\n",
    "\n",
    "# Количество ложные стимулов\n",
    "number_of_mismatch = 4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T17:21:48.887002Z",
     "start_time": "2024-04-01T17:21:48.883345Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "experiment_folder = os.path.dirname(file)\n",
    "\n",
    "# Load the config file\n",
    "with open(os.path.join(experiment_folder, \"src/mylib/utils/config.json\")) as file_path:\n",
    "    config = json.load(file_path)\n",
    "\n",
    "# Path to the dataset, which is already split to train, val, test\n",
    "data_folder = os.path.join(config[\"dataset_folder\"], config['derivatives_folder'], config[\"split_folder\"])\n",
    "\n",
    "# Пути к данным тренировочным, валидационным и тестовым данным\n",
    "train_files = [x for x in glob.glob(os.path.join(data_folder, \"train_-_*\")) if\n",
    "                       os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in [\"eeg\", \"envelope\"]]\n",
    "val_files = [x for x in glob.glob(os.path.join(data_folder, \"val_-_*\")) if\n",
    "                       os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in [\"eeg\", \"envelope\"]]\n",
    "test_files = [x for x in glob.glob(os.path.join(data_folder, \"test_-_*\")) if\n",
    "                       os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in [\"eeg\", \"envelope\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T17:21:48.897759Z",
     "start_time": "2024-04-01T17:21:48.887963Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19nb_usNqXkc"
   },
   "source": [
    "## Обучение "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Базовое решение"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# model = BaselineModel()\n",
    "args = {\"window_length\" : window_length, \"hop_length\" : hop_length, \"number_of_mismatch\" : number_of_mismatch, \"batch_size\" : batch_size, \n",
    "        \"max_files\" : 100}\n",
    "for model in [BaselineModel, MHAModel]:\n",
    "    model = model()\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model, train_files, val_files, test_files, args, torch.optim.Adam(model.parameters(), lr=0.001), torch.nn.CrossEntropyLoss(), \n",
    "    )\n",
    "\n",
    "    trainer.train_model(epochs=5, run_name=f\"{model.__class__.__name__}\")\n",
    "    print(trainer.test())\n",
    "    print(\"-----\" * 5)"
   ],
   "metadata": {
    "id": "ZMK7mqNQZPXJ",
    "outputId": "a95524d6-db85-4a34-9c36-fa2befec2f34",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-04-01T17:30:37.468006Z",
     "start_time": "2024-04-01T17:21:48.898678Z"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 100 loss: 0.1482216489744413\n",
      "  batch 200 loss: 0.0002496870611862123\n",
      "  batch 300 loss: 0.0004293969416104437\n",
      "  batch 400 loss: 0.00014352307940049714\n",
      "  batch 500 loss: 0.0003824394412247301\n",
      "  batch 600 loss: 0.0005175532017259399\n",
      "  batch 700 loss: 0.00033389098716623877\n",
      "  batch 800 loss: 8.32907846506714e-05\n",
      "  batch 900 loss: 2.4057848494294377e-05\n",
      "LOSS train 2.4057848494294377e-05 valid 0.0\n",
      "EPOCH 2:\n",
      "  batch 100 loss: 2.239500692658325e-05\n",
      "  batch 200 loss: 1.717424765956821e-07\n",
      "  batch 300 loss: 2.382965994911501e-06\n",
      "  batch 400 loss: 2.0097729375834205e-07\n",
      "  batch 500 loss: 5.319957272149622e-06\n",
      "  batch 600 loss: 4.880248161498457e-07\n",
      "  batch 700 loss: 7.180011834861944e-08\n",
      "  batch 800 loss: 1.2190427505487378e-06\n",
      "  batch 900 loss: 2.3094077732821461e-07\n",
      "LOSS train 2.3094077732821461e-07 valid 0.0\n",
      "EPOCH 3:\n",
      "  batch 100 loss: 1.9006388822617737e-06\n",
      "  batch 200 loss: 1.8029883719350436e-08\n",
      "  batch 300 loss: 5.650982788552028e-07\n",
      "  batch 400 loss: 3.155075988914291e-08\n",
      "  batch 500 loss: 2.0160868007224052e-06\n",
      "  batch 600 loss: 1.7061551261576823e-07\n",
      "  batch 700 loss: 1.929664222188876e-08\n",
      "  batch 800 loss: 5.126564428525882e-07\n",
      "  batch 900 loss: 6.992110229475657e-08\n",
      "LOSS train 6.992110229475657e-08 valid 0.0\n",
      "EPOCH 4:\n",
      "  batch 100 loss: 8.588485644622779e-07\n",
      "  batch 200 loss: 5.774140259262595e-09\n",
      "  batch 300 loss: 2.494339387482114e-07\n",
      "  batch 400 loss: 8.158223745446947e-09\n",
      "  batch 500 loss: 1.0297044354956597e-06\n",
      "  batch 600 loss: 7.403204108413774e-08\n",
      "  batch 700 loss: 6.612346510337375e-09\n",
      "  batch 800 loss: 2.495401167823541e-07\n",
      "  batch 900 loss: 2.607663617482103e-08\n",
      "LOSS train 2.607663617482103e-08 valid 0.0\n",
      "EPOCH 5:\n",
      "  batch 100 loss: 4.253824216959856e-07\n",
      "  batch 200 loss: 2.067528156457499e-09\n",
      "  batch 300 loss: 1.1764754141552203e-07\n",
      "  batch 400 loss: 2.4027991685215965e-09\n",
      "  batch 500 loss: 5.495035293279216e-07\n",
      "  batch 600 loss: 3.333958602524944e-08\n",
      "  batch 700 loss: 2.384180106673739e-09\n",
      "  batch 800 loss: 1.2554179193102755e-07\n",
      "  batch 900 loss: 1.0691511533877929e-08\n",
      "LOSS train 1.0691511533877929e-08 valid 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1551\n",
      "           1       0.99      1.00      1.00      1524\n",
      "           2       0.99      1.00      0.99      1501\n",
      "           3       0.99      0.99      0.99      1475\n",
      "           4       0.99      1.00      0.99      1507\n",
      "\n",
      "    accuracy                           0.99      7558\n",
      "   macro avg       0.99      0.99      0.99      7558\n",
      "weighted avg       0.99      0.99      0.99      7558\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "colab": {
   "name": "main.ipynb",
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
