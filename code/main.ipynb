{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-23T16:38:58.995403Z",
     "start_time": "2024-04-23T16:38:56.408265Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import torch \n",
    "import numpy as np\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.eeg_to_audio.utils.data import TaskDataset\n",
    "from src.eeg_to_audio.models.models import Model\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Гиперпараметры",
   "id": "2571a32558e605d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T16:38:58.999571Z",
     "start_time": "2024-04-23T16:38:58.996654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Размер батча\n",
    "batch_size = 64\n",
    "\n",
    "# Длина окна\n",
    "window_length_seconds = 5 \n",
    "sample_rate = 64\n",
    "window_length = window_length_seconds * sample_rate\n",
    "\n",
    "# Расстояние между двумя окнами\n",
    "hop_length_seconds = 1\n",
    "hop_length = sample_rate * hop_length_seconds\n",
    "\n",
    "# Количество ложных стимулов\n",
    "number_of_mismatch = 4\n",
    "\n",
    "max_files = None"
   ],
   "id": "26bb2c5e1572941c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Подготовим данные для обучения и тестирования моделей",
   "id": "e76898a4eb241667"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T16:38:59.015490Z",
     "start_time": "2024-04-23T16:38:59.000857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Путь к директории проекта\n",
    "project_path = os.path.dirname(os.path.abspath(\"\"))\n",
    "preds_path = os.path.join(project_path, \"code/predictions\")\n",
    "os.makedirs(preds_path, exist_ok=True)\n",
    "\n",
    "# Загрузим конфигурационный файл\n",
    "with open(os.path.join(project_path, \"src/mylib/utils/config.json\")) as file_path:\n",
    "    config = json.load(file_path)\n",
    "\n",
    "# Путь к набору данных, который уже разделен на train, test\n",
    "data_folder = os.path.join(config[\"dataset_folder\"], config['derivatives_folder'], config[\"split_folder\"])\n",
    "\n",
    "# Тренировочные данные\n",
    "train_files = [x for x in glob.glob(os.path.join(data_folder, \"train_-_*\")) if\n",
    "                       os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in [\"eeg\", \"envelope\"]]\n",
    "\n",
    "# Тестовые данные\n",
    "test_files = [x for x in glob.glob(os.path.join(data_folder, \"test_-_*\")) if\n",
    "                       os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in [\"eeg\", \"envelope\"]]\n",
    "\n",
    "# Разделение на субъекты/участники\n",
    "subjects = list(set([os.path.basename(x).split(\"_-_\")[1] for x in test_files]))"
   ],
   "id": "baa03ad72b35e3af",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dataloader для обучения моделей",
   "id": "dc2b11238eaa3e9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T04:11:00.190364Z",
     "start_time": "2024-04-23T04:07:21.773899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    TaskDataset(train_files, window_length, hop_length, number_of_mismatch, max_files=max_files), \n",
    "    batch_size=batch_size)"
   ],
   "id": "7814ce079903caf7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Функции для обучения ",
   "id": "a0aebb9e7c85ed9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T16:39:43.027381Z",
     "start_time": "2024-04-23T16:39:40.133620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "def train_one_epoch(model, epoch_index, writer, optimizer, loss_fn):\n",
    "    \"\"\"Обучение на одной эпохе\"\"\"\n",
    "\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            x = epoch_index * len(train_dataloader) + i + 1\n",
    "            writer.add_scalar('Loss/train', last_loss, x)\n",
    "            running_loss = 0\n",
    "\n",
    "    return last_loss\n",
    "\n",
    "def train_model(model, epochs, run_name, optimizer, loss_fn):\n",
    "    \"\"\"Обучение модели\"\"\"\n",
    "\n",
    "    writer = SummaryWriter(f\"runs/{run_name}\")\n",
    "\n",
    "    if not os.path.isdir(\"saved_models\"):\n",
    "        os.makedirs(\"saved_models\")\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"EPOCH {epoch + 1}:\")\n",
    "        \n",
    "        avg_loss = train_one_epoch(model, epoch + 1, writer, optimizer, loss_fn)\n",
    "\n",
    "        print(f\"LOSS train {avg_loss}\")\n",
    "        writer.add_scalar(\"Training\", avg_loss, epoch + 1)\n",
    "        writer.flush()\n",
    "\n",
    "        model_path = f\"saved_models/{run_name}_{epoch + 1}\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "def test_model(model, name, use_embeddings, embedding_type):\n",
    "    accuracies = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for sub in subjects:\n",
    "            sub_test_files = [f for f in test_files if sub in os.path.basename(f)]\n",
    "            sub_dataset = TaskDataset(\n",
    "                files=sub_test_files, \n",
    "                window_length=window_length, \n",
    "                hop_length=hop_length,\n",
    "                number_of_mismatch=number_of_mismatch, \n",
    "                max_files=None, \n",
    "                use_embeddings=use_embeddings, \n",
    "                embedding_type=embedding_type\n",
    "            )\n",
    "            test_dataloader = torch.utils.data.DataLoader(sub_dataset, batch_size=1)\n",
    "            loss = 0\n",
    "            correct = 0\n",
    "            for inputs, label in test_dataloader:\n",
    "                outputs = model(inputs)\n",
    "                loss += F.cross_entropy(outputs, label).item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct += (predicted == label).long().item()\n",
    "                \n",
    "            mean_per_sub = correct / len(test_dataloader)\n",
    "            accuracies.append(mean_per_sub)\n",
    "    results_path = os.path.join(preds_path, f\"{name}.json\")\n",
    "    with open(results_path, \"w\") as f:\n",
    "        json.dump(accuracies, f)\n",
    "    return accuracies\n",
    "        \n",
    "def find_best_model(model, prefix, use_embeddings, embedding_type):\n",
    "    best_model_idx = 1\n",
    "    best_mean_accuracy = 0\n",
    "    for i in range(10): # количество эпох\n",
    "        model_path = f\"{prefix}_{i + 1}\"\n",
    "        model_name = os.path.basename(model_path)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        print(f\"Testing {os.path.basename(model_name)}\")\n",
    "        accuracies = test_model(model, model_name, use_embeddings, embedding_type)\n",
    "        print(f\"    Score: {np.mean(accuracies) * 100}\")\n",
    "        print(f\"    Standard deviation: {np.std(accuracies) * 100}\")\n",
    "        if np.mean(accuracies) > best_mean_accuracy:\n",
    "            best_mean_accuracy = np.mean(accuracies)\n",
    "            best_model_idx = i + 1\n",
    "    print(f\"Best model: {prefix}_{best_model_idx}\")\n",
    "    print(f\"Best mean accuracy over subjects: {best_mean_accuracy * 100}\")"
   ],
   "id": "6c69420592f0df47",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 19:39:40.850329: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-23 19:39:42.255194: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Обучение моделей",
   "id": "9c46ae0ae28eb7f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Базовое решение ",
   "id": "824eb80926bceae2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T21:44:48.326159Z",
     "start_time": "2024-04-21T20:51:12.589732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "train_model(model, 10, \"Baseline\", optimizer, loss_fn)"
   ],
   "id": "d008321be12bd358",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 1.4236116971969603\n",
      "  batch 2000 loss: 1.3350688633173704\n",
      "  batch 3000 loss: 1.2263945920690895\n",
      "  batch 4000 loss: 1.1100922726839781\n",
      "  batch 5000 loss: 1.1574973969608546\n",
      "  batch 6000 loss: 1.0699141708165407\n",
      "  batch 7000 loss: 0.9060650415495038\n",
      "  batch 8000 loss: 0.8751413805114571\n",
      "  batch 9000 loss: 0.8953722582366318\n",
      "LOSS train 0.8953722582366318\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 1.2430362387001515\n",
      "  batch 2000 loss: 1.0368988644480706\n",
      "  batch 3000 loss: 1.0211635073125362\n",
      "  batch 4000 loss: 0.9859314801990986\n",
      "  batch 5000 loss: 1.074497663706541\n",
      "  batch 6000 loss: 0.9084391695093363\n",
      "  batch 7000 loss: 0.7152104988954961\n",
      "  batch 8000 loss: 0.8110165086437482\n",
      "  batch 9000 loss: 0.7241114568758349\n",
      "LOSS train 0.7241114568758349\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 1.204264582335949\n",
      "  batch 2000 loss: 0.970810384966433\n",
      "  batch 3000 loss: 1.0264518781602383\n",
      "  batch 4000 loss: 0.9271645446121692\n",
      "  batch 5000 loss: 1.0622857927083968\n",
      "  batch 6000 loss: 0.9164367970526218\n",
      "  batch 7000 loss: 0.7208280336204916\n",
      "  batch 8000 loss: 0.9360015702377131\n",
      "  batch 9000 loss: 0.9232694681007415\n",
      "LOSS train 0.9232694681007415\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 1.1902054367065429\n",
      "  batch 2000 loss: 0.9722909015864134\n",
      "  batch 3000 loss: 0.9617631036527455\n",
      "  batch 4000 loss: 0.8517733554802835\n",
      "  batch 5000 loss: 1.033728141784668\n",
      "  batch 6000 loss: 0.8994903325214982\n",
      "  batch 7000 loss: 0.6897116717267782\n",
      "  batch 8000 loss: 0.8219835635807831\n",
      "  batch 9000 loss: 0.7600965994466096\n",
      "LOSS train 0.7600965994466096\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 1.139733092725277\n",
      "  batch 2000 loss: 0.972569331087172\n",
      "  batch 3000 loss: 0.9953363630920649\n",
      "  batch 4000 loss: 0.9318365859538317\n",
      "  batch 5000 loss: 1.0737341532111169\n",
      "  batch 6000 loss: 0.8796706411167979\n",
      "  batch 7000 loss: 0.7218843805510551\n",
      "  batch 8000 loss: 1.0104869420059257\n",
      "  batch 9000 loss: 0.997686789315194\n",
      "LOSS train 0.997686789315194\n",
      "EPOCH 6:\n",
      "  batch 1000 loss: 1.2466836310625076\n",
      "  batch 2000 loss: 0.9807127006463706\n",
      "  batch 3000 loss: 0.9910042348578573\n",
      "  batch 4000 loss: 0.9583915013223886\n",
      "  batch 5000 loss: 1.0625549178123475\n",
      "  batch 6000 loss: 0.8832067368291319\n",
      "  batch 7000 loss: 0.7523462375253439\n",
      "  batch 8000 loss: 0.7748261362081393\n",
      "  batch 9000 loss: 0.7446451654620468\n",
      "LOSS train 0.7446451654620468\n",
      "EPOCH 7:\n",
      "  batch 1000 loss: 1.1359410219043493\n",
      "  batch 2000 loss: 0.964291112974286\n",
      "  batch 3000 loss: 0.9338053983971476\n",
      "  batch 4000 loss: 0.9325858757831156\n",
      "  batch 5000 loss: 1.0514350917637347\n",
      "  batch 6000 loss: 0.8917387813925743\n",
      "  batch 7000 loss: 0.7993398481812328\n",
      "  batch 8000 loss: 0.8826355085510295\n",
      "  batch 9000 loss: 0.7198264632243663\n",
      "LOSS train 0.7198264632243663\n",
      "EPOCH 8:\n",
      "  batch 1000 loss: 1.1536644019782543\n",
      "  batch 2000 loss: 0.9350532902181149\n",
      "  batch 3000 loss: 0.9169159403629601\n",
      "  batch 4000 loss: 0.9308703474737704\n",
      "  batch 5000 loss: 1.0519394890069962\n",
      "  batch 6000 loss: 0.8652022551521659\n",
      "  batch 7000 loss: 0.7031670067952945\n",
      "  batch 8000 loss: 0.7511090448739706\n",
      "  batch 9000 loss: 0.6865214989967644\n",
      "LOSS train 0.6865214989967644\n",
      "EPOCH 9:\n",
      "  batch 1000 loss: 1.0998311751335859\n",
      "  batch 2000 loss: 0.9046436602324247\n",
      "  batch 3000 loss: 0.9377213105633855\n",
      "  batch 4000 loss: 0.9037969083860516\n",
      "  batch 5000 loss: 1.0162651647031307\n",
      "  batch 6000 loss: 0.8372591467499733\n",
      "  batch 7000 loss: 0.7079794231336564\n",
      "  batch 8000 loss: 0.8460207191204536\n",
      "  batch 9000 loss: 0.7678570295069367\n",
      "LOSS train 0.7678570295069367\n",
      "EPOCH 10:\n",
      "  batch 1000 loss: 1.183451634556055\n",
      "  batch 2000 loss: 0.9364605045504868\n",
      "  batch 3000 loss: 0.9688515525683761\n",
      "  batch 4000 loss: 0.9373456575572491\n",
      "  batch 5000 loss: 1.0912192753553391\n",
      "  batch 6000 loss: 0.8819341793656349\n",
      "  batch 7000 loss: 0.7557311216378585\n",
      "  batch 8000 loss: 0.829687246765825\n",
      "  batch 9000 loss: 0.7034796063228278\n",
      "LOSS train 0.7034796063228278\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Трансформер-кодировщик",
   "id": "99dcbedd9b309966"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T06:52:03.755283Z",
     "start_time": "2024-04-23T04:11:02.680866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Model(use_transformer=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "train_model(model, 10, \"Transformer\", optimizer, loss_fn)"
   ],
   "id": "6fe9fa7744004411",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bukkacha/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 1000 loss: 1.478800526380539\n",
      "  batch 2000 loss: 1.4153387330174445\n",
      "  batch 3000 loss: 1.2953025230169297\n",
      "  batch 4000 loss: 1.2047291131913662\n",
      "  batch 5000 loss: 1.2352882451713085\n",
      "  batch 6000 loss: 1.149226269185543\n",
      "  batch 7000 loss: 0.9131390470564366\n",
      "  batch 8000 loss: 0.9533479110375047\n",
      "  batch 9000 loss: 0.8801870014816523\n",
      "LOSS train 0.8801870014816523\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 1.3204181343317032\n",
      "  batch 2000 loss: 1.1332785344421863\n",
      "  batch 3000 loss: 1.1625599875301122\n",
      "  batch 4000 loss: 1.060022843196988\n",
      "  batch 5000 loss: 1.1211522375941276\n",
      "  batch 6000 loss: 0.9693181176781654\n",
      "  batch 7000 loss: 0.7233105075024069\n",
      "  batch 8000 loss: 0.8794877903144807\n",
      "  batch 9000 loss: 0.7624318301044405\n",
      "LOSS train 0.7624318301044405\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 1.2457961226701737\n",
      "  batch 2000 loss: 1.0385510069206356\n",
      "  batch 3000 loss: 1.066134143039584\n",
      "  batch 4000 loss: 0.9746390198022127\n",
      "  batch 5000 loss: 1.0916806876957417\n",
      "  batch 6000 loss: 0.9601199959143997\n",
      "  batch 7000 loss: 0.7394852414913475\n",
      "  batch 8000 loss: 0.8409614602681249\n",
      "  batch 9000 loss: 0.6960355920530855\n",
      "LOSS train 0.6960355920530855\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 1.168516600996256\n",
      "  batch 2000 loss: 0.9444943787753582\n",
      "  batch 3000 loss: 0.9730337286069989\n",
      "  batch 4000 loss: 0.9104513649940491\n",
      "  batch 5000 loss: 1.0269077167809009\n",
      "  batch 6000 loss: 0.9084340846464037\n",
      "  batch 7000 loss: 0.6884772899262607\n",
      "  batch 8000 loss: 0.7556901865475811\n",
      "  batch 9000 loss: 0.6588564848527312\n",
      "LOSS train 0.6588564848527312\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 1.134864903897047\n",
      "  batch 2000 loss: 0.8801507242396474\n",
      "  batch 3000 loss: 0.8894404000081122\n",
      "  batch 4000 loss: 0.8755927526652812\n",
      "  batch 5000 loss: 1.0074099271446466\n",
      "  batch 6000 loss: 0.8718112771883607\n",
      "  batch 7000 loss: 0.644796799056232\n",
      "  batch 8000 loss: 0.7333941414379515\n",
      "  batch 9000 loss: 0.6251574372127652\n",
      "LOSS train 0.6251574372127652\n",
      "EPOCH 6:\n",
      "  batch 1000 loss: 1.0718771714568138\n",
      "  batch 2000 loss: 0.8365207278504968\n",
      "  batch 3000 loss: 0.851751823792234\n",
      "  batch 4000 loss: 0.8479445902258158\n",
      "  batch 5000 loss: 0.9827756280303002\n",
      "  batch 6000 loss: 0.8066440588161349\n",
      "  batch 7000 loss: 0.5920982176847756\n",
      "  batch 8000 loss: 0.7234545132727362\n",
      "  batch 9000 loss: 0.6028483335170894\n",
      "LOSS train 0.6028483335170894\n",
      "EPOCH 7:\n",
      "  batch 1000 loss: 1.043292405575514\n",
      "  batch 2000 loss: 0.8190321180559694\n",
      "  batch 3000 loss: 0.8368524838518351\n",
      "  batch 4000 loss: 0.8284345306828618\n",
      "  batch 5000 loss: 0.9786395684555173\n",
      "  batch 6000 loss: 0.7713389440141618\n",
      "  batch 7000 loss: 0.5827296452689916\n",
      "  batch 8000 loss: 0.666417561022332\n",
      "  batch 9000 loss: 0.5851223947480321\n",
      "LOSS train 0.5851223947480321\n",
      "EPOCH 8:\n",
      "  batch 1000 loss: 1.0258575632870197\n",
      "  batch 2000 loss: 0.7947452431730926\n",
      "  batch 3000 loss: 0.8274569044299424\n",
      "  batch 4000 loss: 0.8235836750417947\n",
      "  batch 5000 loss: 0.9699082221537828\n",
      "  batch 6000 loss: 0.8110549866259098\n",
      "  batch 7000 loss: 0.5744474236182868\n",
      "  batch 8000 loss: 0.6425125700249337\n",
      "  batch 9000 loss: 0.5915185625106096\n",
      "LOSS train 0.5915185625106096\n",
      "EPOCH 9:\n",
      "  batch 1000 loss: 1.016498616695404\n",
      "  batch 2000 loss: 0.7732753108609468\n",
      "  batch 3000 loss: 0.8080240316409618\n",
      "  batch 4000 loss: 0.8094916131906211\n",
      "  batch 5000 loss: 0.9601760019958019\n",
      "  batch 6000 loss: 0.8049664133600891\n",
      "  batch 7000 loss: 0.5920126751642674\n",
      "  batch 8000 loss: 0.6692474644260946\n",
      "  batch 9000 loss: 0.6166136038657278\n",
      "LOSS train 0.6166136038657278\n",
      "EPOCH 10:\n",
      "  batch 1000 loss: 1.0010965014994144\n",
      "  batch 2000 loss: 0.7633660705555231\n",
      "  batch 3000 loss: 0.7740739350216463\n",
      "  batch 4000 loss: 0.7937243749573827\n",
      "  batch 5000 loss: 0.938383444339037\n",
      "  batch 6000 loss: 0.7701147777512669\n",
      "  batch 7000 loss: 0.5625182293867692\n",
      "  batch 8000 loss: 0.6328268445387948\n",
      "  batch 9000 loss: 0.5689217851022258\n",
      "LOSS train 0.5689217851022258\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Wav2Vec2",
   "id": "69388a8a1b716e71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T11:14:40.581129Z",
     "start_time": "2024-04-23T11:11:09.341057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    TaskDataset(\n",
    "        train_files, \n",
    "        window_length, \n",
    "        hop_length, \n",
    "        number_of_mismatch, \n",
    "        use_embeddings=True,\n",
    "        embedding_type=\"wav2vec\",\n",
    "        max_files=max_files\n",
    "    ), \n",
    "    batch_size=batch_size)"
   ],
   "id": "1bba2ed97994ad55",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:27:05.156878Z",
     "start_time": "2024-04-22T02:00:50.481189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Model(use_embeddings=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "train_model(model, 10, \"Wav2Vec2\", optimizer, loss_fn)"
   ],
   "id": "9e7a8288bd45ee2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 1.3662997370362282\n",
      "  batch 2000 loss: 1.3435519411116839\n",
      "  batch 3000 loss: 1.231669880270958\n",
      "  batch 4000 loss: 1.1406536244452\n",
      "  batch 5000 loss: 1.2572615306079387\n",
      "  batch 6000 loss: 1.0864462063163518\n",
      "  batch 7000 loss: 0.947474068036303\n",
      "  batch 8000 loss: 0.9424286197645124\n",
      "  batch 9000 loss: 0.8118643170073628\n",
      "LOSS train 0.8118643170073628\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 1.272037116199732\n",
      "  batch 2000 loss: 1.0826246792450547\n",
      "  batch 3000 loss: 0.9904180364981293\n",
      "  batch 4000 loss: 0.9230534630846232\n",
      "  batch 5000 loss: 1.0704123395681382\n",
      "  batch 6000 loss: 0.9424439346529543\n",
      "  batch 7000 loss: 0.753140829268843\n",
      "  batch 8000 loss: 0.940974034695886\n",
      "  batch 9000 loss: 0.7553026258163155\n",
      "LOSS train 0.7553026258163155\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 1.2101848999261855\n",
      "  batch 2000 loss: 1.0929499887935816\n",
      "  batch 3000 loss: 1.0496226754039526\n",
      "  batch 4000 loss: 0.9977835546210408\n",
      "  batch 5000 loss: 1.1074906907081603\n",
      "  batch 6000 loss: 0.9139102460853755\n",
      "  batch 7000 loss: 0.7434386727977544\n",
      "  batch 8000 loss: 0.9221609901769552\n",
      "  batch 9000 loss: 0.9309021462984383\n",
      "LOSS train 0.9309021462984383\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 1.1847485366761685\n",
      "  batch 2000 loss: 1.1934402299150824\n",
      "  batch 3000 loss: 0.9853205630853772\n",
      "  batch 4000 loss: 0.9153792227357626\n",
      "  batch 5000 loss: 1.0503113304972649\n",
      "  batch 6000 loss: 0.8923244463279844\n",
      "  batch 7000 loss: 0.6385250081727282\n",
      "  batch 8000 loss: 0.861315400043095\n",
      "  batch 9000 loss: 0.7307851973194629\n",
      "LOSS train 0.7307851973194629\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 1.1907727763354778\n",
      "  batch 2000 loss: 1.1109568883031606\n",
      "  batch 3000 loss: 1.0188109104931355\n",
      "  batch 4000 loss: 0.9438970411531628\n",
      "  batch 5000 loss: 1.1061096045523882\n",
      "  batch 6000 loss: 0.9008714128248394\n",
      "  batch 7000 loss: 0.7152325253300369\n",
      "  batch 8000 loss: 0.8374616655969294\n",
      "  batch 9000 loss: 0.6885463172001764\n",
      "LOSS train 0.6885463172001764\n",
      "EPOCH 6:\n",
      "  batch 1000 loss: 1.1601628796160222\n",
      "  batch 2000 loss: 0.962809518314898\n",
      "  batch 3000 loss: 0.9332042429894208\n",
      "  batch 4000 loss: 0.906501600638032\n",
      "  batch 5000 loss: 1.0987661987245083\n",
      "  batch 6000 loss: 0.8965592547208071\n",
      "  batch 7000 loss: 0.703668380420655\n",
      "  batch 8000 loss: 0.8629406648764852\n",
      "  batch 9000 loss: 0.6960572732612491\n",
      "LOSS train 0.6960572732612491\n",
      "EPOCH 7:\n",
      "  batch 1000 loss: 1.1397840220928193\n",
      "  batch 2000 loss: 0.9744927016533911\n",
      "  batch 3000 loss: 0.9046887677460909\n",
      "  batch 4000 loss: 0.8938645010106265\n",
      "  batch 5000 loss: 1.085424124494195\n",
      "  batch 6000 loss: 0.8867489930614829\n",
      "  batch 7000 loss: 0.7313389321248979\n",
      "  batch 8000 loss: 0.8366441852252465\n",
      "  batch 9000 loss: 0.6937303390922025\n",
      "LOSS train 0.6937303390922025\n",
      "EPOCH 8:\n",
      "  batch 1000 loss: 1.1247475525438786\n",
      "  batch 2000 loss: 1.0190349378585815\n",
      "  batch 3000 loss: 0.9368462494686246\n",
      "  batch 4000 loss: 0.8998664898532442\n",
      "  batch 5000 loss: 1.0688759801089764\n",
      "  batch 6000 loss: 0.8842073211744428\n",
      "  batch 7000 loss: 0.7952894375286996\n",
      "  batch 8000 loss: 0.8376248937656637\n",
      "  batch 9000 loss: 0.6816882583599072\n",
      "LOSS train 0.6816882583599072\n",
      "EPOCH 9:\n",
      "  batch 1000 loss: 1.1256589244902133\n",
      "  batch 2000 loss: 1.0256536247730255\n",
      "  batch 3000 loss: 0.9230037379860878\n",
      "  batch 4000 loss: 0.918380692910403\n",
      "  batch 5000 loss: 1.1182034894227981\n",
      "  batch 6000 loss: 0.8957712020799518\n",
      "  batch 7000 loss: 0.7849381890054792\n",
      "  batch 8000 loss: 0.8478042397624813\n",
      "  batch 9000 loss: 0.6737360821429175\n",
      "LOSS train 0.6737360821429175\n",
      "EPOCH 10:\n",
      "  batch 1000 loss: 1.104626755386591\n",
      "  batch 2000 loss: 1.0112681879326701\n",
      "  batch 3000 loss: 0.9124713986944407\n",
      "  batch 4000 loss: 0.8991294299662114\n",
      "  batch 5000 loss: 1.0985099084079266\n",
      "  batch 6000 loss: 0.9081669860854745\n",
      "  batch 7000 loss: 0.7713312346134334\n",
      "  batch 8000 loss: 0.8339847441418097\n",
      "  batch 9000 loss: 0.6751159531087615\n",
      "LOSS train 0.6751159531087615\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Wav2Vec2 + Трансформер-кодировщик",
   "id": "965b7958519cbd16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:04:00.930744Z",
     "start_time": "2024-04-23T11:14:40.582263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Model(use_transformer=True, use_embeddings=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "train_model(model, 10, \"Wav2Vec2_Transformer\", optimizer, loss_fn)"
   ],
   "id": "a4654dc4b5241c5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bukkacha/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 1000 loss: 1.4447205238938332\n",
      "  batch 2000 loss: 1.4130910626649857\n",
      "  batch 3000 loss: 1.2888768396973609\n",
      "  batch 4000 loss: 1.2102454049885274\n",
      "  batch 5000 loss: 1.299887429535389\n",
      "  batch 6000 loss: 1.2342196773290635\n",
      "  batch 7000 loss: 1.0774298080429434\n",
      "  batch 8000 loss: 1.0283029739372431\n",
      "  batch 9000 loss: 0.9198296899050474\n",
      "LOSS train 0.9198296899050474\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 1.291153755068779\n",
      "  batch 2000 loss: 1.2350445881485939\n",
      "  batch 3000 loss: 1.1618102525621652\n",
      "  batch 4000 loss: 1.1117135928571225\n",
      "  batch 5000 loss: 1.223812633961439\n",
      "  batch 6000 loss: 1.1147157388329505\n",
      "  batch 7000 loss: 0.9200177744477988\n",
      "  batch 8000 loss: 0.9740746207442135\n",
      "  batch 9000 loss: 0.8489593121334911\n",
      "LOSS train 0.8489593121334911\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 1.219773182928562\n",
      "  batch 2000 loss: 1.1385985208451748\n",
      "  batch 3000 loss: 1.0581673898249864\n",
      "  batch 4000 loss: 1.0140426948070527\n",
      "  batch 5000 loss: 1.1334198258966208\n",
      "  batch 6000 loss: 0.9884603485614062\n",
      "  batch 7000 loss: 0.8157191476151348\n",
      "  batch 8000 loss: 0.9149282250739634\n",
      "  batch 9000 loss: 0.7664807034395635\n",
      "LOSS train 0.7664807034395635\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 1.1614343536496163\n",
      "  batch 2000 loss: 1.0679999431818723\n",
      "  batch 3000 loss: 1.0020411729887129\n",
      "  batch 4000 loss: 0.9447011305987835\n",
      "  batch 5000 loss: 1.0802546095103025\n",
      "  batch 6000 loss: 0.9314323001205921\n",
      "  batch 7000 loss: 0.7616065925434232\n",
      "  batch 8000 loss: 0.8786981835523621\n",
      "  batch 9000 loss: 0.7161024227943271\n",
      "LOSS train 0.7161024227943271\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 1.120692682504654\n",
      "  batch 2000 loss: 1.0309591212570668\n",
      "  batch 3000 loss: 0.9540412084981799\n",
      "  batch 4000 loss: 0.8957420110851526\n",
      "  batch 5000 loss: 1.0476900338679551\n",
      "  batch 6000 loss: 0.8874378327950835\n",
      "  batch 7000 loss: 0.7279924630522728\n",
      "  batch 8000 loss: 0.8358063391428441\n",
      "  batch 9000 loss: 0.6937489352077246\n",
      "LOSS train 0.6937489352077246\n",
      "EPOCH 6:\n",
      "  batch 1000 loss: 1.094599018007517\n",
      "  batch 2000 loss: 0.9854071418195963\n",
      "  batch 3000 loss: 0.9115949983671308\n",
      "  batch 4000 loss: 0.8660436928495765\n",
      "  batch 5000 loss: 1.0261038768291473\n",
      "  batch 6000 loss: 0.8724022793322802\n",
      "  batch 7000 loss: 0.7042156041897834\n",
      "  batch 8000 loss: 0.8075774878591765\n",
      "  batch 9000 loss: 0.6812287392462604\n",
      "LOSS train 0.6812287392462604\n",
      "EPOCH 7:\n",
      "  batch 1000 loss: 1.074714778393507\n",
      "  batch 2000 loss: 0.9421014052033424\n",
      "  batch 3000 loss: 0.8822904854603112\n",
      "  batch 4000 loss: 0.8504824254363775\n",
      "  batch 5000 loss: 1.01439274469018\n",
      "  batch 6000 loss: 0.8465677652359008\n",
      "  batch 7000 loss: 0.6847989632897079\n",
      "  batch 8000 loss: 0.7854915829496458\n",
      "  batch 9000 loss: 0.6653161401692778\n",
      "LOSS train 0.6653161401692778\n",
      "EPOCH 8:\n",
      "  batch 1000 loss: 1.0415090781450271\n",
      "  batch 2000 loss: 0.9075941446498036\n",
      "  batch 3000 loss: 0.8515967079810798\n",
      "  batch 4000 loss: 0.8305183217898011\n",
      "  batch 5000 loss: 1.0077337331026792\n",
      "  batch 6000 loss: 0.8325214779004455\n",
      "  batch 7000 loss: 0.6627965834923089\n",
      "  batch 8000 loss: 0.761512348456541\n",
      "  batch 9000 loss: 0.6490731919491664\n",
      "LOSS train 0.6490731919491664\n",
      "EPOCH 9:\n",
      "  batch 1000 loss: 1.0156664361953736\n",
      "  batch 2000 loss: 0.8686356251388788\n",
      "  batch 3000 loss: 0.8339704810678958\n",
      "  batch 4000 loss: 0.8195594321861863\n",
      "  batch 5000 loss: 0.9955766025409103\n",
      "  batch 6000 loss: 0.8153382996320725\n",
      "  batch 7000 loss: 0.644393153861165\n",
      "  batch 8000 loss: 0.7469637961182743\n",
      "  batch 9000 loss: 0.6359310435540975\n",
      "LOSS train 0.6359310435540975\n",
      "EPOCH 10:\n",
      "  batch 1000 loss: 0.986614647090435\n",
      "  batch 2000 loss: 0.8391513234376907\n",
      "  batch 3000 loss: 0.8099210518300534\n",
      "  batch 4000 loss: 0.80628586884588\n",
      "  batch 5000 loss: 0.9862047719061374\n",
      "  batch 6000 loss: 0.7908602937050164\n",
      "  batch 7000 loss: 0.6328926154226064\n",
      "  batch 8000 loss: 0.7154293488347903\n",
      "  batch 9000 loss: 0.6195094019612297\n",
      "LOSS train 0.6195094019612297\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Whisper",
   "id": "2f59cfcd6f989b88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T07:56:27.757792Z",
     "start_time": "2024-04-23T07:53:22.229929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    TaskDataset(\n",
    "        train_files, \n",
    "        window_length, \n",
    "        hop_length, \n",
    "        number_of_mismatch, \n",
    "        use_embeddings=True,\n",
    "        embedding_type=\"whisper\",\n",
    "        max_files=max_files\n",
    "    ), \n",
    "    batch_size=batch_size)"
   ],
   "id": "5f07af257ba4a7b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:34:30.850856Z",
     "start_time": "2024-04-23T07:56:35.577611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Model(use_embeddings=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "train_model(model, 10, \"Whisper\", optimizer, loss_fn)"
   ],
   "id": "5e5b754cee7fc440",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 1.530054544687271\n",
      "  batch 2000 loss: 1.5085525208413602\n",
      "  batch 3000 loss: 1.388169602394104\n",
      "  batch 4000 loss: 1.3246328034996986\n",
      "  batch 5000 loss: 1.3454550401270389\n",
      "  batch 6000 loss: 1.322010199278593\n",
      "  batch 7000 loss: 1.216881231099367\n",
      "  batch 8000 loss: 1.0325167435631155\n",
      "  batch 9000 loss: 0.9929398702755571\n",
      "LOSS train 0.9929398702755571\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 1.3499571793675422\n",
      "  batch 2000 loss: 1.2822652371823788\n",
      "  batch 3000 loss: 1.2339162350296975\n",
      "  batch 4000 loss: 1.1991217382550239\n",
      "  batch 5000 loss: 1.2615520667135716\n",
      "  batch 6000 loss: 1.211245310306549\n",
      "  batch 7000 loss: 0.9937756114900113\n",
      "  batch 8000 loss: 0.9865182080548257\n",
      "  batch 9000 loss: 0.8998065079674125\n",
      "LOSS train 0.8998065079674125\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 1.2882275751829146\n",
      "  batch 2000 loss: 1.1816454423069953\n",
      "  batch 3000 loss: 1.1621199712455272\n",
      "  batch 4000 loss: 1.1194220950603486\n",
      "  batch 5000 loss: 1.2181407805383206\n",
      "  batch 6000 loss: 1.1030537429451943\n",
      "  batch 7000 loss: 0.8760644637048245\n",
      "  batch 8000 loss: 0.9421006445055827\n",
      "  batch 9000 loss: 0.8515718759782612\n",
      "LOSS train 0.8515718759782612\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 1.2417325071096421\n",
      "  batch 2000 loss: 1.0991934617459773\n",
      "  batch 3000 loss: 1.1067146421819924\n",
      "  batch 4000 loss: 1.0487651641070843\n",
      "  batch 5000 loss: 1.1592019089460373\n",
      "  batch 6000 loss: 1.0188588525056839\n",
      "  batch 7000 loss: 0.8096793936565518\n",
      "  batch 8000 loss: 0.9143400713610463\n",
      "  batch 9000 loss: 0.8258470754735172\n",
      "LOSS train 0.8258470754735172\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 1.1966312893629074\n",
      "  batch 2000 loss: 1.0597514555901288\n",
      "  batch 3000 loss: 1.0545460225045682\n",
      "  batch 4000 loss: 0.9902846170440316\n",
      "  batch 5000 loss: 1.1176888161003589\n",
      "  batch 6000 loss: 0.9749638677090406\n",
      "  batch 7000 loss: 0.7766565635800362\n",
      "  batch 8000 loss: 0.9001295753018931\n",
      "  batch 9000 loss: 0.8031379514075816\n",
      "LOSS train 0.8031379514075816\n",
      "EPOCH 6:\n",
      "  batch 1000 loss: 1.157260344147682\n",
      "  batch 2000 loss: 1.0384999296963215\n",
      "  batch 3000 loss: 1.012768816024065\n",
      "  batch 4000 loss: 0.9521806369051338\n",
      "  batch 5000 loss: 1.1002476128190757\n",
      "  batch 6000 loss: 0.9404241435304284\n",
      "  batch 7000 loss: 0.743168437987566\n",
      "  batch 8000 loss: 0.8899935110518709\n",
      "  batch 9000 loss: 0.7861683803834021\n",
      "LOSS train 0.7861683803834021\n",
      "EPOCH 7:\n",
      "  batch 1000 loss: 1.1254720349907874\n",
      "  batch 2000 loss: 1.021167283564806\n",
      "  batch 3000 loss: 0.9760968947708607\n",
      "  batch 4000 loss: 0.9256955797262489\n",
      "  batch 5000 loss: 1.0855314186364413\n",
      "  batch 6000 loss: 0.9137417494431138\n",
      "  batch 7000 loss: 0.7144042487218976\n",
      "  batch 8000 loss: 0.863278262254782\n",
      "  batch 9000 loss: 0.7714375276006759\n",
      "LOSS train 0.7714375276006759\n",
      "EPOCH 8:\n",
      "  batch 1000 loss: 1.1040111649930477\n",
      "  batch 2000 loss: 0.9892067238539457\n",
      "  batch 3000 loss: 0.951157874032855\n",
      "  batch 4000 loss: 0.9057417023554444\n",
      "  batch 5000 loss: 1.0737537702471018\n",
      "  batch 6000 loss: 0.8874545524194837\n",
      "  batch 7000 loss: 0.6916488109193742\n",
      "  batch 8000 loss: 0.8421347533380613\n",
      "  batch 9000 loss: 0.7607838632315397\n",
      "LOSS train 0.7607838632315397\n",
      "EPOCH 9:\n",
      "  batch 1000 loss: 1.087695717304945\n",
      "  batch 2000 loss: 0.958586086332798\n",
      "  batch 3000 loss: 0.9334706511422992\n",
      "  batch 4000 loss: 0.892445919085294\n",
      "  batch 5000 loss: 1.0631211225688457\n",
      "  batch 6000 loss: 0.8620143338218331\n",
      "  batch 7000 loss: 0.6712508687265217\n",
      "  batch 8000 loss: 0.8267448940845207\n",
      "  batch 9000 loss: 0.7507324857115746\n",
      "LOSS train 0.7507324857115746\n",
      "EPOCH 10:\n",
      "  batch 1000 loss: 1.073228529751301\n",
      "  batch 2000 loss: 0.9353497190177441\n",
      "  batch 3000 loss: 0.9180630413964391\n",
      "  batch 4000 loss: 0.8835656238012016\n",
      "  batch 5000 loss: 1.0546168510764837\n",
      "  batch 6000 loss: 0.8455677112340927\n",
      "  batch 7000 loss: 0.6563257888872176\n",
      "  batch 8000 loss: 0.8187859972640872\n",
      "  batch 9000 loss: 0.7391014576870948\n",
      "LOSS train 0.7391014576870948\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Whisper + Трансформер-кодировщик",
   "id": "58238e80adf243d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T11:06:48.589723Z",
     "start_time": "2024-04-23T08:36:26.993262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Model(use_transformer=True, use_embeddings=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "train_model(model, 10, \"Whisper_Transformer\", optimizer, loss_fn)"
   ],
   "id": "5de5cdb8c5e11d62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 1.4692934195399285\n",
      "  batch 2000 loss: 1.4516245831251144\n",
      "  batch 3000 loss: 1.2963569405376911\n",
      "  batch 4000 loss: 1.2403112150132656\n",
      "  batch 5000 loss: 1.3123895798027516\n",
      "  batch 6000 loss: 1.239592512458563\n",
      "  batch 7000 loss: 1.2398733949661256\n",
      "  batch 8000 loss: 1.0470608564019204\n",
      "  batch 9000 loss: 0.8900982885435224\n",
      "LOSS train 0.8900982885435224\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 1.2603485351800918\n",
      "  batch 2000 loss: 1.1966750031709672\n",
      "  batch 3000 loss: 1.1270521369874478\n",
      "  batch 4000 loss: 1.0945382124856113\n",
      "  batch 5000 loss: 1.1754349231123924\n",
      "  batch 6000 loss: 1.0157934419810772\n",
      "  batch 7000 loss: 0.8412438865676523\n",
      "  batch 8000 loss: 1.1288031111583114\n",
      "  batch 9000 loss: 0.964851033680141\n",
      "LOSS train 0.964851033680141\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 1.174999808192253\n",
      "  batch 2000 loss: 1.178183576092124\n",
      "  batch 3000 loss: 1.0567990419715643\n",
      "  batch 4000 loss: 0.9985540768764913\n",
      "  batch 5000 loss: 1.1337618932723998\n",
      "  batch 6000 loss: 0.9582912397235632\n",
      "  batch 7000 loss: 0.7890062080658973\n",
      "  batch 8000 loss: 1.0009602517960594\n",
      "  batch 9000 loss: 0.8536358360350133\n",
      "LOSS train 0.8536358360350133\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 1.1412850564122201\n",
      "  batch 2000 loss: 1.0886935369074344\n",
      "  batch 3000 loss: 1.0169938042014837\n",
      "  batch 4000 loss: 0.9702294040210545\n",
      "  batch 5000 loss: 1.1107879127562046\n",
      "  batch 6000 loss: 0.9258044503182172\n",
      "  batch 7000 loss: 0.7512602799423039\n",
      "  batch 8000 loss: 0.8980133224725724\n",
      "  batch 9000 loss: 0.749732170291245\n",
      "LOSS train 0.749732170291245\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 1.131013804525137\n",
      "  batch 2000 loss: 0.9949904806762934\n",
      "  batch 3000 loss: 0.9899846984744072\n",
      "  batch 4000 loss: 0.9639712561145425\n",
      "  batch 5000 loss: 1.102371985346079\n",
      "  batch 6000 loss: 0.8994056794419885\n",
      "  batch 7000 loss: 0.732002362973988\n",
      "  batch 8000 loss: 0.830133864318952\n",
      "  batch 9000 loss: 0.6898602365897969\n",
      "LOSS train 0.6898602365897969\n",
      "EPOCH 6:\n",
      "  batch 1000 loss: 1.1130606657862663\n",
      "  batch 2000 loss: 0.9377019721865654\n",
      "  batch 3000 loss: 0.9670338564664125\n",
      "  batch 4000 loss: 0.9421059684008359\n",
      "  batch 5000 loss: 1.08253983810544\n",
      "  batch 6000 loss: 0.8699407961443066\n",
      "  batch 7000 loss: 0.724375913720578\n",
      "  batch 8000 loss: 0.791928086867556\n",
      "  batch 9000 loss: 0.6692504327055067\n",
      "LOSS train 0.6692504327055067\n",
      "EPOCH 7:\n",
      "  batch 1000 loss: 1.094588048875332\n",
      "  batch 2000 loss: 0.9037243054509163\n",
      "  batch 3000 loss: 0.9447248020246625\n",
      "  batch 4000 loss: 0.9216567677855492\n",
      "  batch 5000 loss: 1.07329159553349\n",
      "  batch 6000 loss: 0.8498693820871412\n",
      "  batch 7000 loss: 0.7192977921888232\n",
      "  batch 8000 loss: 0.7731054913792759\n",
      "  batch 9000 loss: 0.65714320041053\n",
      "LOSS train 0.65714320041053\n",
      "EPOCH 8:\n",
      "  batch 1000 loss: 1.0803124362826346\n",
      "  batch 2000 loss: 0.8817882535755635\n",
      "  batch 3000 loss: 0.9243628664761782\n",
      "  batch 4000 loss: 0.9051985762864351\n",
      "  batch 5000 loss: 1.0614275213479996\n",
      "  batch 6000 loss: 0.8376454390883445\n",
      "  batch 7000 loss: 0.7125412913300097\n",
      "  batch 8000 loss: 0.759149994475767\n",
      "  batch 9000 loss: 0.6495952834412455\n",
      "LOSS train 0.6495952834412455\n",
      "EPOCH 9:\n",
      "  batch 1000 loss: 1.0645906628072261\n",
      "  batch 2000 loss: 0.8690632534474134\n",
      "  batch 3000 loss: 0.8963580782935023\n",
      "  batch 4000 loss: 0.8902388335745781\n",
      "  batch 5000 loss: 1.0518156872987747\n",
      "  batch 6000 loss: 0.8237308763042093\n",
      "  batch 7000 loss: 0.7118529961407185\n",
      "  batch 8000 loss: 0.7551755850296468\n",
      "  batch 9000 loss: 0.6408865540907718\n",
      "LOSS train 0.6408865540907718\n",
      "EPOCH 10:\n",
      "  batch 1000 loss: 1.0530750629901886\n",
      "  batch 2000 loss: 0.8610038653686642\n",
      "  batch 3000 loss: 0.8733276482149959\n",
      "  batch 4000 loss: 0.8743845928162336\n",
      "  batch 5000 loss: 1.040672594115138\n",
      "  batch 6000 loss: 0.8170256504192949\n",
      "  batch 7000 loss: 0.702590917468071\n",
      "  batch 8000 loss: 0.7474030318465084\n",
      "  batch 9000 loss: 0.6288994920314289\n",
      "LOSS train 0.6288994920314289\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Тестирование моделей",
   "id": "ba68934fa7d4ead3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T21:23:46.882644Z",
     "start_time": "2024-04-22T20:44:31.238970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Baseline\n",
    "model = Model()\n",
    "find_best_model(model, \"saved_models/Baseline\", use_embeddings=False, embedding_type=None)"
   ],
   "id": "66722985ab17f2ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Baseline_1\n",
      "    Score: 39.360677658368246\n",
      "    Standard deviation: 8.651644625493846\n",
      "Testing Baseline_2\n",
      "    Score: 46.66444428993618\n",
      "    Standard deviation: 11.359896796031574\n",
      "Testing Baseline_3\n",
      "    Score: 45.96438560624621\n",
      "    Standard deviation: 11.182113087018115\n",
      "Testing Baseline_4\n",
      "    Score: 46.440096065481924\n",
      "    Standard deviation: 11.01103218593001\n",
      "Testing Baseline_5\n",
      "    Score: 44.80580518390737\n",
      "    Standard deviation: 10.705961941627889\n",
      "Testing Baseline_6\n",
      "    Score: 46.359484367436\n",
      "    Standard deviation: 11.511476317401828\n",
      "Testing Baseline_7\n",
      "    Score: 46.79768675465637\n",
      "    Standard deviation: 11.489560573190417\n",
      "Testing Baseline_8\n",
      "    Score: 47.68028231894928\n",
      "    Standard deviation: 11.7532132984657\n",
      "Testing Baseline_9\n",
      "    Score: 45.818900961757144\n",
      "    Standard deviation: 10.255576511151649\n",
      "Testing Baseline_10\n",
      "    Score: 45.98206954063792\n",
      "    Standard deviation: 10.364910983815669\n",
      "Best model: saved_models/Baseline_8\n",
      "Best mean accuracy over subjects: 47.68028231894928\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T07:51:51.939099Z",
     "start_time": "2024-04-23T06:53:05.919021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# transformer\n",
    "model = Model(use_transformer=True)\n",
    "find_best_model(model, \"saved_models/Transformer\", use_embeddings=False, embedding_type=None)"
   ],
   "id": "2cccdbf701dc3627",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Transformer_1\n",
      "    Score: 39.0940746710181\n",
      "    Standard deviation: 6.0620562089009065\n",
      "Testing Transformer_2\n",
      "    Score: 42.82136347214697\n",
      "    Standard deviation: 7.608204772168582\n",
      "Testing Transformer_3\n",
      "    Score: 43.86994840651148\n",
      "    Standard deviation: 8.64796062179662\n",
      "Testing Transformer_4\n",
      "    Score: 46.99608369553099\n",
      "    Standard deviation: 9.69434147599378\n",
      "Testing Transformer_5\n",
      "    Score: 47.38630537800766\n",
      "    Standard deviation: 10.11790195830794\n",
      "Testing Transformer_6\n",
      "    Score: 46.81368532476631\n",
      "    Standard deviation: 9.172093270112075\n",
      "Testing Transformer_7\n",
      "    Score: 46.94043750966656\n",
      "    Standard deviation: 10.050665221015153\n",
      "Testing Transformer_8\n",
      "    Score: 48.14620389539536\n",
      "    Standard deviation: 10.325968545729618\n",
      "Testing Transformer_9\n",
      "    Score: 47.76784312538807\n",
      "    Standard deviation: 10.368920975904734\n",
      "Testing Transformer_10\n",
      "    Score: 47.92992166567605\n",
      "    Standard deviation: 9.996836650151128\n",
      "Best model: saved_models/Transformer_8\n",
      "Best mean accuracy over subjects: 48.14620389539536\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T22:36:38.596747Z",
     "start_time": "2024-04-22T22:15:42.280486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# wav2vec\n",
    "model = Model(use_embeddings=True)\n",
    "find_best_model(model, \"saved_models/Wav2Vec2\", use_embeddings=True, embedding_type=\"wav2vec\")"
   ],
   "id": "9caa7b4e5962675e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Wav2Vec2_1\n",
      "    Score: 41.82758925036238\n",
      "    Standard deviation: 10.080636249381419\n",
      "Testing Wav2Vec2_2\n",
      "    Score: 46.362373542103626\n",
      "    Standard deviation: 10.871913835124452\n",
      "Testing Wav2Vec2_3\n",
      "    Score: 38.70606376805536\n",
      "    Standard deviation: 7.059814477162425\n",
      "Testing Wav2Vec2_4\n",
      "    Score: 45.83871448503402\n",
      "    Standard deviation: 10.82189235658003\n",
      "Testing Wav2Vec2_5\n",
      "    Score: 47.924381652937356\n",
      "    Standard deviation: 11.538437697974684\n",
      "Testing Wav2Vec2_6\n",
      "    Score: 47.82545052845452\n",
      "    Standard deviation: 11.903177220611463\n",
      "Testing Wav2Vec2_7\n",
      "    Score: 44.39463305420997\n",
      "    Standard deviation: 10.020710351271953\n",
      "Testing Wav2Vec2_8\n",
      "    Score: 45.44762857460445\n",
      "    Standard deviation: 10.048801686961005\n",
      "Testing Wav2Vec2_9\n",
      "    Score: 44.0328294023473\n",
      "    Standard deviation: 9.764226518065867\n",
      "Testing Wav2Vec2_10\n",
      "    Score: 43.97768376093069\n",
      "    Standard deviation: 10.037348620764808\n",
      "Best model: saved_models/Wav2Vec2_5\n",
      "Best mean accuracy over subjects: 47.924381652937356\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:17:03.678800Z",
     "start_time": "2024-04-23T16:39:51.290901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# wav2vec + transformer\n",
    "model = Model(use_transformer=True, use_embeddings=True)\n",
    "find_best_model(model, \"saved_models/Wav2Vec2_Transformer\", use_embeddings=True, embedding_type=\"wav2vec\")"
   ],
   "id": "67f92c7962816fb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Wav2Vec2_Transformer_1\n",
      "    Score: 39.22095959597641\n",
      "    Standard deviation: 7.578864991908082\n",
      "Testing Wav2Vec2_Transformer_2\n",
      "    Score: 43.02705780223626\n",
      "    Standard deviation: 8.559468564404776\n",
      "Testing Wav2Vec2_Transformer_3\n",
      "    Score: 45.696212950223256\n",
      "    Standard deviation: 8.968160150457736\n",
      "Testing Wav2Vec2_Transformer_4\n",
      "    Score: 46.1559558269976\n",
      "    Standard deviation: 9.408322690545964\n",
      "Testing Wav2Vec2_Transformer_5\n",
      "    Score: 46.96316553286621\n",
      "    Standard deviation: 9.780992723900253\n",
      "Testing Wav2Vec2_Transformer_6\n",
      "    Score: 48.19426273293928\n",
      "    Standard deviation: 9.411968383689235\n",
      "Testing Wav2Vec2_Transformer_7\n",
      "    Score: 48.69892030159866\n",
      "    Standard deviation: 9.439039200528606\n",
      "Testing Wav2Vec2_Transformer_8\n",
      "    Score: 48.260723004420484\n",
      "    Standard deviation: 9.46619078038726\n",
      "Testing Wav2Vec2_Transformer_9\n",
      "    Score: 47.986688157266784\n",
      "    Standard deviation: 9.437650927981997\n",
      "Testing Wav2Vec2_Transformer_10\n",
      "    Score: 48.438421034094766\n",
      "    Standard deviation: 9.136160893565688\n",
      "Best model: saved_models/Wav2Vec2_Transformer_7\n",
      "Best mean accuracy over subjects: 48.69892030159866\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:39:07.413286Z",
     "start_time": "2024-04-23T17:17:03.680239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# whisper \n",
    "model = Model(use_embeddings=True)\n",
    "find_best_model(model, \"saved_models/Whisper\", use_embeddings=True, embedding_type=\"whisper\")"
   ],
   "id": "f7c2da3bd37637ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Whisper_1\n",
      "    Score: 39.84660788809597\n",
      "    Standard deviation: 7.2947474042744656\n",
      "Testing Whisper_2\n",
      "    Score: 43.735993438818596\n",
      "    Standard deviation: 8.831191371701143\n",
      "Testing Whisper_3\n",
      "    Score: 45.686518112939005\n",
      "    Standard deviation: 9.082655335555541\n",
      "Testing Whisper_4\n",
      "    Score: 46.68009377243776\n",
      "    Standard deviation: 9.31487373864925\n",
      "Testing Whisper_5\n",
      "    Score: 46.62679452747467\n",
      "    Standard deviation: 8.920854240151153\n",
      "Testing Whisper_6\n",
      "    Score: 46.61873055145058\n",
      "    Standard deviation: 9.11657367637659\n",
      "Testing Whisper_7\n",
      "    Score: 47.28265710744356\n",
      "    Standard deviation: 8.771947626061971\n",
      "Testing Whisper_8\n",
      "    Score: 47.44124544095504\n",
      "    Standard deviation: 9.490552286052582\n",
      "Testing Whisper_9\n",
      "    Score: 47.19368303805454\n",
      "    Standard deviation: 9.295528695858446\n",
      "Testing Whisper_10\n",
      "    Score: 48.0394324213252\n",
      "    Standard deviation: 9.850522191075745\n",
      "Best model: saved_models/Whisper_10\n",
      "Best mean accuracy over subjects: 48.0394324213252\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T18:13:57.989261Z",
     "start_time": "2024-04-23T17:39:07.414295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# whisper + transformer\n",
    "model = Model(use_transformer=True, use_embeddings=True)\n",
    "find_best_model(model, \"saved_models/Whisper_Transformer\", use_embeddings=True, embedding_type=\"whisper\")"
   ],
   "id": "f1a6442f20e6f954",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Whisper_Transformer_1\n",
      "    Score: 43.130965200886976\n",
      "    Standard deviation: 7.474750364054375\n",
      "Testing Whisper_Transformer_2\n",
      "    Score: 44.36198707310336\n",
      "    Standard deviation: 7.624153534560188\n",
      "Testing Whisper_Transformer_3\n",
      "    Score: 46.481840948455954\n",
      "    Standard deviation: 8.379141407222217\n",
      "Testing Whisper_Transformer_4\n",
      "    Score: 47.82768780215764\n",
      "    Standard deviation: 9.527966293717169\n",
      "Testing Whisper_Transformer_5\n",
      "    Score: 47.436809031532604\n",
      "    Standard deviation: 9.200021856967187\n",
      "Testing Whisper_Transformer_6\n",
      "    Score: 47.86471731764808\n",
      "    Standard deviation: 9.144051575107168\n",
      "Testing Whisper_Transformer_7\n",
      "    Score: 47.714506782082026\n",
      "    Standard deviation: 9.458328558034058\n",
      "Testing Whisper_Transformer_8\n",
      "    Score: 48.35524197758893\n",
      "    Standard deviation: 9.243531524106075\n",
      "Testing Whisper_Transformer_9\n",
      "    Score: 47.93589091150331\n",
      "    Standard deviation: 9.34330270781373\n",
      "Testing Whisper_Transformer_10\n",
      "    Score: 47.92263334389318\n",
      "    Standard deviation: 9.327856524119154\n",
      "Best model: saved_models/Whisper_Transformer_8\n",
      "Best mean accuracy over subjects: 48.35524197758893\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Отобразим результаты на графике",
   "id": "ed920d7e8275a3fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T19:18:13.240188Z",
     "start_time": "2024-04-24T19:18:13.077556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path_to_preds = os.path.join(project_path, \"code/predictions\")\n",
    "predictions = []\n",
    "for model_name in [\"Baseline_8\", \"Transformer_8\", \"Wav2Vec2_5\", \"Wav2Vec2_Transformer_7\", \"Whisper_10\", \"Whisper_Transformer_8\"]:\n",
    "    with open(os.path.join(path_to_preds, f\"{model_name}.json\"), \"r\") as f:\n",
    "        predictions.append(np.array(json.load(f)))\n",
    "predictions = np.array(predictions).T\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.boxplot(predictions, labels=[\"Baseline\", \"Transformer Encoder\", \"Wav2Vec2\", \"Wav2Vec2 +\\n Transformer Encoder\", \"Whisper-small\", \"Whisper-small +\\nTransformer Encoder\"])\n",
    "plt.axhline(y=np.median(predictions.T[0]), linestyle=\"--\", color='black')\n",
    "plt.ylabel(\"Accuracy per subject\")\n",
    "plt.show()"
   ],
   "id": "c352676838a29996",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
